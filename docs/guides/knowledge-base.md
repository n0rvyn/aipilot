# 知识库使用指南

本指南详细说明如何使用 AIPilot 的知识库（RAG）功能，让 AI 基于你的笔记来回答问题。

## 📚 什么是知识库？

知识库功能使用 RAG（Retrieval-Augmented Generation）技术：

1. **检索** - 从你的笔记中找到相关内容
2. **增强** - 将相关内容作为上下文提供给 AI
3. **生成** - AI 基于你的笔记生成答案

**优势**:
- ✅ 基于你的知识回答
- ✅ 减少 AI 幻觉
- ✅ 提供信息来源
- ✅ 利用本地知识库

## 🚀 快速开始

### 1. 配置嵌入模型

首先需要配置用于文本检索的嵌入模型：

1. 打开 `设置` → `AIPilot`
2. 找到 `嵌入模型` 部分
3. 选择模型：
   - OpenAI: `text-embedding-3-small` (推荐)
   - 智谱 AI: `embedding-3`

### 2. 启用知识库

在聊天界面：

1. 点击 `启用知识库` 开关
2. 输入你的问题
3. AI 会自动检索相关笔记并基于它们回答

### 3. 查看来源

回答下方会显示参考来源：

```
📄 来源：
1. [[笔记A]] - 相似度: 0.89
2. [[笔记B]] - 相似度: 0.82
3. [[笔记C]] - 相似度: 0.75
```

点击笔记名可以跳转查看原文。

## 🎯 使用场景

### 场景 1: 学习笔记查询

**笔记内容**:
```markdown
# 量子计算基础

量子计算利用量子力学原理进行信息处理...

## 量子比特
与传统比特不同，量子比特可以处于叠加态...

## 量子纠缠
两个量子比特可以纠缠在一起...
```

**查询**:
```
问：什么是量子纠缠？

答：基于你的笔记《量子计算基础》，量子纠缠是指
两个量子比特可以纠缠在一起的现象...

来源：[[量子计算基础]]
```

### 场景 2: 项目文档检索

**笔记结构**:
```
项目笔记/
├── 技术方案.md
├── API文档.md
└── 会议记录.md
```

**查询**:
```
问：我们的 API 认证方案是什么？

答：根据你的技术方案和 API 文档，我们使用 JWT
进行认证...具体实现如下...

来源：
- [[技术方案]]
- [[API文档]]
```

### 场景 3: 阅读笔记汇总

**查询**:
```
问：总结我阅读的关于时间管理的所有笔记

答：综合你的阅读笔记，时间管理的核心要点包括：
1. 优先级管理（来自《高效能人士的七个习惯》）
2. 番茄工作法（来自《番茄工作法图解》）
3. GTD 方法（来自《尽管去做》）
...

来源：[列出所有相关笔记]
```

## ⚙️ 高级配置

### 检索参数调整

在设置中可以调整 RAG 参数：

#### 检索数量 (Limit)

控制返回多少个相关笔记。

| 值 | 适用场景 |
|----|---------|
| 3 | 快速简单查询 |
| 5 | 标准使用（默认） |
| 10+ | 全面深入分析 |

#### 相似度阈值 (Similarity Threshold)

控制笔记必须有多相关才会被使用。

| 值 | 效果 |
|----|------|
| 0.8+ | 只返回高度相关的笔记 |
| 0.6-0.7 | 标准相关度（推荐） |
| < 0.5 | 广泛搜索，可能包含不太相关的内容 |

#### Lambda 参数

平衡相关性和多样性。

| 值 | 行为 |
|----|------|
| 0.9 | 注重相关性，可能有重复内容 |
| 0.7 | 平衡（默认） |
| 0.5 | 注重多样性，覆盖更多角度 |

### 查询增强

#### 启用查询重写

**作用**: 将你的问题改写成多个变体，提高检索准确率。

**示例**:
```
原始查询：如何提高效率？

重写后：
- 效率提升方法
- 时间管理技巧
- 生产力工具推荐
```

**建议**: 通常开启

#### 启用 HyDE

**作用**: 生成一个"假设的理想答案"，用它来检索。

**适用**: 查询比较模糊时效果好

**成本**: 额外的 API 调用

**建议**: 复杂查询时开启

#### 启用反思

**作用**: AI 评估自己的答案质量，如果不满意会重新尝试。

**效果**: 显著提高答案质量

**成本**: 增加响应时间和 API 调用

**建议**: 重要查询时开启

## 📝 最佳实践

### 1. 优化笔记结构

**好的笔记结构**:
```markdown
# 清晰的标题

## 使用小标题分段

每段内容聚焦一个主题。

使用列表整理要点：
- 要点 1
- 要点 2

## 相关链接

[[相关笔记A]]
[[相关笔记B]]
```

**避免**:
- 过长的段落（> 1000 字）
- 没有结构的流水账
- 过多无关内容

### 2. 使用清晰的问题

**好的问题**:
```
❌ 差: "那个东西"
✅ 好: "什么是量子纠缠？"

❌ 差: "告诉我一些事"
✅ 好: "总结我关于项目管理的笔记"

❌ 差: "怎么办？"
✅ 好: "如何解决内存泄漏问题？"
```

### 3. 限制检索范围

**使用目录过滤**:

在设置中可以限制只在特定文件夹搜索：

```
RAG 设置 → 检索目录: "工作笔记/"
```

**好处**:
- 提高相关性
- 加快检索速度
- 避免无关内容

### 4. 定期整理笔记

**建议**:
- 使用一致的命名规范
- 添加标签便于分类
- 定期合并碎片笔记
- 删除过时内容

### 5. 清理缓存

知识库会缓存笔记的 embedding，如果笔记有大量更新：

```
设置 → AIPilot → RAG 设置 → 清空缓存
```

## 🎨 实用技巧

### 技巧 1: 组合使用手动引用

```
参考 [[我的笔记]]，并结合知识库中的其他相关内容，
请详细解释...
```

### 技巧 2: 渐进式查询

```
第一次：什么是主题？
第二次：详细展开第二点
第三次：给我一个实际例子
```

### 技巧 3: 交叉验证

```
查询：根据我的笔记，A 和 B 有什么关系？

AI 会检索所有提到 A 和 B 的笔记并分析它们的关系。
```

### 技巧 4: 知识图谱查询

```
查询：列出我笔记中关于 X 的所有关键概念及其关系

AI 会汇总多个笔记构建知识图谱。
```

## 🐛 故障排查

### 问题 1: 没有找到相关笔记

**可能原因**:
- 相似度阈值太高
- 笔记内容与查询不够相关
- 缓存需要更新

**解决方案**:
1. 降低相似度阈值到 0.5
2. 增加检索数量到 10
3. 清空缓存
4. 尝试不同的查询方式

### 问题 2: 返回的笔记不相关

**可能原因**:
- 相似度阈值太低
- Lambda 参数不合适

**解决方案**:
1. 提高相似度阈值到 0.7
2. 使用更具体的查询
3. 启用查询重写

### 问题 3: 响应速度慢

**可能原因**:
- 检索数量太多
- 启用了 HyDE 和反思
- 笔记库太大

**解决方案**:
1. 减少检索数量到 3
2. 关闭 HyDE 和反思
3. 使用目录过滤限制范围
4. 考虑拆分大型笔记

### 问题 4: 缓存占用太多内存

**解决方案**:
```
设置 → AIPilot → RAG 设置 → 清空缓存
```

定期清理或设置自动清理规则。

## 📊 性能优化

### 优化 1: 智能分块

对于长笔记，系统会自动分块：

```
长笔记 (5000 字)
    ↓
分成多个语义块
    ↓
每个块独立检索
    ↓
使用最相关的块
```

### 优化 2: 增量索引

系统只会重新索引修改过的笔记：

```
检测文件修改时间
    ↓
只重新计算改变的文件
    ↓
更新缓存
```

### 优化 3: 批量处理

首次使用时批量处理所有笔记：

```
显示进度条
    ↓
批量计算 embedding (100 个/批)
    ↓
缓存所有结果
```

## 🔒 隐私考虑

### 数据处理

1. **本地处理**: 大部分处理在本地完成
2. **API 调用**: 只有 embedding 和 生成 需要调用 API
3. **不存储**: API 提供商通常不存储请求数据
4. **可控**: 你可以选择不使用 RAG 功能

### 敏感信息

**建议**:
- 不要在敏感笔记中存储明文密码
- 可以使用目录过滤排除敏感文件夹
- 考虑使用本地模型（未来功能）

## 🔮 未来功能

计划中的增强：

- [ ] 混合检索（关键词 + 语义）
- [ ] 图片和表格检索
- [ ] 时间线检索（查询特定时间段的笔记）
- [ ] 关系图谱可视化
- [ ] 本地向量数据库
- [ ] 增量学习（根据反馈优化）

## 🔗 相关文档

- [RAG 系统设计](../architecture/rag-system.md)
- [RAG Service API](../api/rag-service.md)
- [配置指南](configuration.md)

---

**提示**: 知识库的效果取决于笔记的质量！投入时间整理笔记会获得更好的结果。

